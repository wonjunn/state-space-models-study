# state-space-models-study

## papers

<details><summary> <strong> HiPPO: Recurrent Memory with Optimal Polynomial Projections </strong> <code>NeurIPS 2020</code> <a href="https://arxiv.org/abs/2008.07669"><img alt="GitHub release" src="https://img.shields.io/badge/arXiv-2008.07669-b31b1b.svg"></a> </summary>
  
![image](https://github.com/wonjunn/state-space-models-study/assets/60861873/3bbe2dd0-b97f-4456-92fa-d6a8e3e1131b)

</details>

<br>

[26 Oct 2021] <br>
<details><summary> <strong> Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers </strong> <code>NeurIPS 2021</code> <a id='lssl'></a> [<a href="https://arxiv.org/abs/2110.13985">arXiv</a>] [<a href="https://github.com/state-spaces/s4">Github</a>] </summary>
  
![image](https://github.com/wonjunn/state-space-models-study/assets/60861873/3bbe2dd0-b97f-4456-92fa-d6a8e3e1131b)

</details>

[26 Oct 2021] <br>
<h4> Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers </h4> `NeurIPS 2021` <a id='lssl'></a> [[arXiv](https://arxiv.org/abs/2110.13985)] [[Github](https://github.com/state-spaces/s4)]

[31 Oct 2021] <br>
**Efficiently Modeling Long Sequences with Structured State Spaces** `ICLR 2022` <a id='s4'></a> [[arXiv](https://arxiv.org/abs/2111.00396)] [[Github](https://github.com/state-spaces/s4)]

[28 Dec 2022] <br>
**Hungry Hungry Hippos: Towards Language Modeling with State Space Models** `ICLR 2023` <a id='h3'></a> [[arXiv](https://arxiv.org/abs/2212.14052)] [[Github](https://github.com/HazyResearch/H3)]

[1 Dec 2023] <br>
**Mamba: Linear-Time Sequence Modeling with Selective State Spaces** `Preprint` <a id='mamba'></a> [[arXiv](https://arxiv.org/abs/2312.00752)] [[Github](https://github.com/state-spaces/mamba)]
